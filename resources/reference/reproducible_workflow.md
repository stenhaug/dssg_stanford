## Reproducible Workflow Discussion 7/22/2019

### Best Practices for Data Management

As you may have noticed while working on these EDA questions - there's still a lot of messiness in the data - duplicates, etc. Maybe you noticed yourself re-running the same process code over and over again.

Data analysis can get messy - especially if the data is messy.

What we do relies on our input data. It's important to be careful! What would happen if we deleted everyone who had missing data? 

First, read the "Intro", "Data management", and "Project organization" of "Good enough practices in scientific computing" [link](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510). What are your key takeaways from this?

All of your analysis depends on your data processing, so it should be reliable, understandable, automatic, and well documented.

### Organizing projects, pipelines

We'll refer to DSSG-Chicago's reference for structuring [repositories](https://github.com/dssg/hitchhikers-guide/tree/master/sources/curriculum/0_before_you_start/pipelines-and-project-workflow). Create a new git repository with your group and start working here. Your organization structure should match this!





